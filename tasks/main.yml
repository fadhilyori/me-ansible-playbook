---
# Install Docker Binary

- name: Copy Docker Binary Archive to remote target
  ansible.builtin.copy:
    src: "files/{{ docker_archive_filename }}"
    dest: "/tmp/"
    mode: 0644

- name: Extract Docker Binary Archive
  become: true
  ansible.builtin.unarchive:
    src: "/tmp/{{ docker_archive_filename }}"
    dest: "/usr/bin/"
    creates: "/usr/bin/dockerd"
    copy: false
    extra_opts: [--strip-components=1]

- name: Configure Docker systemd file
  become: true
  ansible.builtin.template:
    src: "./dockerd/docker.service.j2"
    dest: "/lib/systemd/system/docker.service"
    owner: root
    group: root
    mode: 0755

- name: Ensure Docker directory exists
  become: true
  ansible.builtin.file:
    path: "/usr/local/lib/docker/cli-plugins"
    mode: 0700
    state: directory

- name: Install Docker Compose plugin
  become: true
  ansible.builtin.copy:
    src: "files/{{ docker_compose_plugin_archive_filename }}"
    dest: "/usr/local/lib/docker/cli-plugins/docker-compose"
    mode: 0755

- name: Restart service cron also issue daemon-reload to pick up config changes
  become: true
  ansible.builtin.systemd:
    state: started
    enabled: true
    daemon_reload: true
    name: docker

# Run Kafka Installation

- name: Ensure Kafka directory exists
  become: true
  file:
    path: "~/kafka"
    state: directory
    mode: 0775

- name: Ensure Kafka docker image dir exists
  become: true
  file:
    path: "~/kafka/docker_image"
    state: directory
    mode: 0775

- name: Copy docker image kafka related files to machine
  become: true
  ansible.builtin.copy:
    src: "files/docker_images/{{ item }}"
    dest: "~/kafka/docker_image/"
    mode: 0644
  with_items:
    - "confluentinc_cp-kafka.tar"
    - "confluentinc_cp-zookeeper.tar"
    - "mataelang_kafka-mqtt-source.tar"
    - "provectuslabs_kafka-ui.tar"
    - "eclipse-mosquitto_2.tar"

- name: Load docker image
  ansible.builtin.shell: docker load -i {{ item }}
  become: true
  args:
    chdir: ~/kafka/docker_image
  with_items:
    - "confluentinc_cp-kafka.tar"
    - "confluentinc_cp-zookeeper.tar"
    - "mataelang_kafka-mqtt-source.tar"
    - "provectuslabs_kafka-ui.tar"
    - "eclipse-mosquitto_2.tar"

- name: Configure docker-compose environment
  ansible.builtin.template: 
    src: ./kafka/docker-compose.yml.j2
    dest: "~/kafka/docker-compose.yml"
    mode: 0755

- name: Ensure Conf directory exists
  file:
    path: "~/kafka/conf"
    state: directory
    mode: 0775

- name: Configure mosquitto environment
  ansible.builtin.template:
    src: ./kafka/conf/mosquitto.conf.j2
    dest: "~/kafka/conf/mosquitto.conf"
    mode: 0755

- name: Configure control-center environment
  ansible.builtin.template: 
    src: ./kafka/conf/control-center.env.j2
    dest: "~/kafka/conf/control-center.env"
    mode: 0755

- name: Configure Kafka environment
  ansible.builtin.template: 
    src: ./kafka/conf/kafka.env.j2
    dest: "~/kafka/conf/kafka.env"
    mode: 0755

- name: Configure MQTT Connect environment
  ansible.builtin.template: 
    src: ./kafka/conf/mqtt-source.env.j2
    dest: "~/kafka/conf/mqtt-source.env"
    mode: 0755

- name: Configure Zookeper environment
  ansible.builtin.template: 
    src: ./kafka/conf/zookeeper.env.j2
    dest: "~/kafka/conf/zookeeper.env"
    mode: 0755

- name: Down compose service
  ansible.builtin.shell: docker compose down -v
  args:
    chdir: ~/kafka

- name: Up compose service
  ansible.builtin.shell: docker compose up --detach
  args:
    chdir: ~/kafka

# Run Snort Sensor Installation

- name: Ensure Sensor directory exists
  file:
    path: "~/sensor"
    state: directory
    mode: 0775

- name: Ensure Sensor docker image dir exists
  file:
    path: "~/sensor/docker_image"
    state: directory
    mode: 0775

- name: Copy docker image kafka related files to machine
  ansible.builtin.copy:
    src: "files/docker_images/{{ item }}"
    dest: "~/sensor/docker_image/"
    mode: 0644
  with_items:
    - "mataelang_snort3-parser.tar"
    - "mataelang_snort-base_3.tar"

- name: Load docker image
  ansible.builtin.shell: docker load -i {{ item }}
  args:
    chdir: ~/sensor/docker_image
  with_items:
    - "mataelang_snort3-parser.tar"
    - "mataelang_snort-base_3.tar"

- name: Configure docker-compose environment
  ansible.builtin.template: 
    src: ./sensor/docker-compose.yml.j2
    dest: "~/sensor/docker-compose.yml"
    mode: 0755

- name: Ensure Snort directory exists
  file:
    path: "~/sensor/snort"
    state: directory
    mode: 0775

- name: Configure Dockerfile environment
  ansible.builtin.template:
    src: "./sensor/snort/Dockerfile.j2"
    dest: "~/sensor/snort/Dockerfile"

- name: Configure pulledpork config file
  ansible.builtin.template:
    src: "./sensor/snort/pulledpork.conf.j2"
    dest: "~/sensor/snort/pulledpork.conf"

- name: Configure snort.lua config file
  ansible.builtin.template:
    src: "./sensor/snort/snort.lua.j2"
    dest: "~/sensor/snort/snort.lua"

- name: Configure local.rules config file
  ansible.builtin.template:
    src: "./sensor/snort/local.rules.j2"
    dest: "~/sensor/snort/local.rules"

- name: Configure start shell config file
  ansible.builtin.template:
    src: ./sensor/snort/start.sh.j2
    dest: "~/sensor/snort/start.sh"

- name: Deploy Docker Compose stack
  community.docker.docker_compose:
    project_src: "~/sensor"
    build: true
    remove_orphans: true
    files:
    - docker-compose.yml

#Run Hadoop Installation
- name: Define hadoop_listen_ip
  ansible.builtin.set_fact:
    hadoop_listen_ip: "{{ __hadoop_listen_ip }}"
  when: hadoop_listen_ip is not defined

- name: Create service account for Apache Hadoop
  become: true
  ansible.builtin.user:
    name: "hadoop"
    home: "/home/hadoop"
    shell: "/bin/bash"
    state: present
    generate_ssh_key: true

- name: Set authorized key taken from file
  become: true
  become_user: hadoop
  ansible.builtin.shell:
    cmd: cat /home/hadoop/.ssh/id_rsa.pub > /home/hadoop/.ssh/authorized_keys

- name: Copy JDK Archive
  ansible.builtin.copy:
    src: "files/{{ jdk_archive_filename }}"
    dest: "/tmp/"
    mode: 0644

- name: Ensure jdk directory exists
  become: true
  ansible.builtin.file:
    path: "{{ item }}"
    mode: 0775
    state: directory
    owner: "hadoop"
    group: "hadoop"
  with_items:
    - "/opt/jdk"
    - "/opt/hadoop"

- name: Extract JDK distribution
  become: true
  ansible.builtin.unarchive:
    src: "/tmp/{{ jdk_archive_filename }}"
    dest: "/opt/jdk"
    creates: "/opt/jdk/bin"
    copy: false
    owner: "hadoop"
    group: "hadoop"
    extra_opts: [--strip-components=1]

- name: Copy Hadoop Archive
  ansible.builtin.copy:
    src: "files/{{ hadoop_archive_filename }}"
    dest: "/tmp/"
    mode: 0644

- name: Extract Hadoop distribution
  become: true
  ansible.builtin.unarchive:
    src: "/tmp/{{ hadoop_archive_filename }}"
    dest: "/opt/hadoop"
    creates: "/opt/hadoop/etc"
    copy: false
    owner: "hadoop"
    group: "hadoop"
    extra_opts: [--strip-components=1]

- name: Configure hadoop-env.sh file
  become: true
  ansible.builtin.template:
    src: "./hadoop/hadoop-env.sh.j2"
    dest: "/opt/hadoop/etc/hadoop/hadoop-env.sh"
    mode: 0755

- name: Configure core-site.xml file
  become: true
  ansible.builtin.template:
    src: "./hadoop/core-site.xml.j2"
    dest: "/opt/hadoop/etc/hadoop/core-site.xml"
    mode: 0755

- name: Configure hdfs-site.xml file
  become: true
  ansible.builtin.template:
    src: "./hadoop/hdfs-site.xml.j2"
    dest: "/opt/hadoop/etc/hadoop/hdfs-site.xml"
    mode: 0755

- name: Stop Hadoop service
  become: true
  ansible.builtin.shell:
    cmd: /opt/hadoop/sbin/stop-dfs.sh

- name: Remove hadoop_data folder
  become: true
  ansible.builtin.file:
    path: /home/hadoop/hadoop_data
    state: absent

- name: Ensure folder logs exist
  become: true
  ansible.builtin.file:
    path: "/opt/hadoop/logs"
    mode: 0775
    state: directory
    owner: "hadoop"
    group: "hadoop"

- name: Format a Hadoop Namenode
  become: true
  become_user: hadoop
  ansible.builtin.shell:
    cmd: /opt/hadoop/bin/hdfs namenode -format

- name: Start Hadoop service
  become: true
  become_user: hadoop
  ansible.builtin.shell:
    cmd: /opt/hadoop/sbin/start-dfs.sh

- name: Copy Kaspacore related file to machine
  ansible.builtin.copy:
    src: "files/{{ item }}"
    dest: "/tmp/"
    mode: 0644
  with_items:
    - "kaspacore.jar"
    - "GeoLite2-City.mmdb"

- name: Pause for 2 minute to wait hadoop starting up
  ansible.builtin.pause:
    minutes: 2

- name: Create Hadoop needed directory
  become: true
  become_user: hadoop
  ansible.builtin.shell:
    cmd: "{{ item }}"
  with_items:
    - "/opt/hadoop/bin/hdfs dfs -mkdir -p hdfs://localhost:9000/user/hadoop/kaspa-checkpoint"
    - "/opt/hadoop/bin/hdfs dfs -mkdir -p hdfs://localhost:9000/user/hadoop/file/maxmind"
    - "/opt/hadoop/bin/hdfs dfs -mkdir -p hdfs://localhost:9000/user/hadoop/spark/spark-events"

- name: Upload GeoLite2-City Maxmind Geo Database
  become: true
  become_user: hadoop
  ansible.builtin.shell:
    cmd: "{{ item }}"
  with_items:
    - "/opt/hadoop/bin/hdfs dfs -put /tmp/GeoLite2-City.mmdb /user/hadoop/file/maxmind"
    - "/opt/hadoop/bin/hdfs dfs -put /tmp/kaspacore.jar /user/hadoop/file"

#Run Spark Installation

- name: Ensure Spark directory exists
  file:
    path: "~/spark"
    state: directory
    mode: 0775

- name: Ensure Spark docker image dir exists
  file:
    path: "~/spark/docker_image"
    state: directory
    mode: 0775

- name: Copy docker image Spark related files to machine
  ansible.builtin.copy:
    src: "files/docker_images/{{ item }}"
    dest: "~/spark/docker_image/"
    mode: 0644
  with_items:
    - "mataelang_spark_3.3.1-scala2.13.tar"

- name: Load docker image
  ansible.builtin.shell: docker load -i {{ item }}
  args:
    chdir: ~/spark/docker_image
  with_items:
    - "mataelang_spark_3.3.1-scala2.13.tar"

- name: Configure docker-compose environment
  ansible.builtin.template: 
    src: ./spark/docker-compose.yml.j2
    dest: "~/spark/docker-compose.yml"
    mode: 0755

- name: Ensure Conf directory exists
  file:
    path: "~/spark/conf"
    state: directory
    mode: 0775

- name: Copy Kaspacore jar file to machine
  ansible.builtin.copy:
    src: "files/{{ item }}"
    dest: "~/spark/"
    mode: 0644
  with_items:
    - "kaspacore.jar"
    - "GeoLite2-City.mmdb"

- name: Ensure Kaspacore Checkpoint directory exists
  become: true
  file:
    path: "~/spark/kafka-checkpoint"
    state: directory
    mode: 0775
    owner: 185
    group: 185

- name: Down compose service
  ansible.builtin.shell: docker compose down -v
  args:
    chdir: ~/spark

- name: Load docker image
  ansible.builtin.shell: docker compose up -d
  args:
    chdir: ~/spark

- name: Pause for 1 minute to build app cache
  ansible.builtin.pause:
    minutes: 1

- name: Change owner of kafka-checkpoint directory
  become: true
  ansible.builtin.shell: chown -R 185:185 kafka-checkpoint
  args:
    chdir: ~/spark

- name: Execute spark-submit command
  ansible.builtin.shell: "{{ item }}"
  args:
    chdir: ~/spark
  with_items:
    - "docker compose exec -it spark-master /opt/spark/bin/spark-submit --master spark://spark-master:7077 --class org.mataelang.kaspacore.jobs.SensorEnrichDataStreamJob --total-executor-cores 1 --conf spark.submit.deployMode=cluster --conf spark.executor.cores=1 --conf spark.executor.memory=1g file:///opt/spark/jars/kaspacore.jar"
    - "docker compose exec -it spark-master /opt/spark/bin/spark-submit --master spark://spark-master:7077 --class org.mataelang.kaspacore.jobs.SensorAggregationStreamJob --total-executor-cores 5 --conf spark.submit.deployMode=cluster --conf spark.executor.cores=1 --conf spark.executor.memory=1g file:///opt/spark/jars/kaspacore.jar"

#Run OpenSearch Installation

- name: Ensure OpenSearch directory exists
  file:
    path: "~/opensearch"
    state: directory
    mode: 0775

- name: Ensure Opensearch docker image dir exists
  file:
    path: "~/opensearch/docker_image"
    state: directory
    mode: 0775

- name: Increase number of memory map using sysctl
  become: true
  ansible.posix.sysctl:
    name: vm.max_map_count
    value: 262144
    state: present

- name: Copy docker image Opensearch related files to machine
  ansible.builtin.copy:
    src: "files/docker_images/{{ item }}"
    dest: "~/opensearch/docker_image/"
    mode: 0644
  with_items:
    - "opensearchproject_logstash-oss-with-opensearch-output-plugin.tar"
    - "opensearchproject_opensearch-dashboards.tar"
    - "opensearchproject_opensearch.tar"

- name: Load docker image
  ansible.builtin.shell: docker load -i {{ item }}
  args:
    chdir: ~/opensearch/docker_image
  with_items:
    - "opensearchproject_logstash-oss-with-opensearch-output-plugin.tar"
    - "opensearchproject_opensearch-dashboards.tar"
    - "opensearchproject_opensearch.tar"

- name: Configure docker-compose environment
  ansible.builtin.template: 
    src: ./opensearch/docker-compose.yaml.j2
    dest: "~/opensearch/docker-compose.yaml"
    mode: 0755

- name: Configure Pipeline config file
  ansible.builtin.template:
    src: ./opensearch/pipeline.conf.j2
    dest: "~/opensearch/pipeline.conf"

- name: deploy Docker Compose stack
  community.docker.docker_compose:
    project_src: "~/opensearch"
    files:
    - docker-compose.yaml