---
- name: Ensure Spark directory exists
  file:
    path: "~/spark"
    state: directory
    mode: 0775

- name: Ensure Spark docker image dir exists
  file:
    path: "~/spark/docker_image"
    state: directory
    mode: 0775

- name: Copy docker image Spark related files to machine
  ansible.builtin.copy:
    src: "files/docker_images/{{ item }}"
    dest: "~/spark/docker_image/"
    mode: 0775
  with_items: "{{ spark_image_filename }}"

- name: Load docker image
  community.docker.docker_image_load:
    docker_host: "unix:/{{ ansible_env.XDG_RUNTIME_DIR }}/docker.sock"
    path: "~/spark/docker_image/{{ item }}"
  with_items: "{{ spark_image_filename }}"

- name: Configure docker-compose environment
  ansible.builtin.template: 
    src: ./spark/docker-compose.yml.j2
    dest: "~/spark/docker-compose.yml"
    mode: 0775

- name: Configure environment file
  ansible.builtin.template: 
    src: ./spark/.env.j2
    dest: "~/spark/.env"
    mode: 0775

- name: Ensure Conf directory exists
  file:
    path: "~/spark/conf"
    state: directory
    mode: 0775

- name: Configure app properties file
  ansible.builtin.template: 
    src: ./spark/conf/app.properties.j2
    dest: "~/spark/conf/app.properties"
    mode: 0775

- name: Configure spark conf file
  ansible.builtin.template: 
    src: ./spark/conf/spark-defaults.conf.j2
    dest: "~/spark/conf/spark-defaults.conf"
    mode: 0775

- name: Configure spark log properties file
  ansible.builtin.template: 
    src: ./spark/conf/log4j2.properties.j2
    dest: "~/spark/conf/log4j2.properties"
    mode: 0775

- name: Copy Kaspacore jar file to machine
  ansible.builtin.copy:
    src: "files/{{ item }}"
    dest: "~/spark/"
    mode: 0755
  with_items:
    - "kaspacore.jar"
    - "GeoLite2-City.mmdb"

- name: Ensure Kaspacore Checkpoint directory exists
  become: true
  file:
    path: "~/spark/kafka-checkpoint"
    state: directory
    mode: 0775
    owner: 185
    group: 185

- name: Check if docker-compose.yaml file exists
  ansible.builtin.stat:
    path: ~/spark/docker-compose.yml
  register: spark_compose_file

- name: Stop the Services
  community.docker.docker_compose:
    docker_host: "unix:/{{ ansible_env.XDG_RUNTIME_DIR }}/docker.sock"
    project_src: ~/spark
    remove_orphans: true
    remove_volumes: true
    state: absent
  when: spark_compose_file.stat.exists

- name: Load docker image
  community.docker.docker_image_load:
    docker_host: "unix:/{{ ansible_env.XDG_RUNTIME_DIR }}/docker.sock"
    path: "~/spark/docker_image/{{ item }}"
  with_items:
    - "mataelang_spark_3.3.1-scala2.13.tar"

- name: Pause for 1 minute to build app cache
  ansible.builtin.pause:
    minutes: 1

- name: Change owner of kafka-checkpoint directory
  become: true
  ansible.builtin.shell: chown -R 185:185 kafka-checkpoint
  args:
    chdir: ~/spark

- name: Running the Services
  community.docker.docker_compose:
    docker_host: "unix:/{{ ansible_env.XDG_RUNTIME_DIR }}/docker.sock"
    project_src: ~/spark
    state: present